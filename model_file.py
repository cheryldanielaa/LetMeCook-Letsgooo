# -*- coding: utf-8 -*-
"""model_catwalk_SGD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jd8xwxnjWIkHTxGiynxotMvIvoq9_Ww8
"""

import csv
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer
import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization, LeakyReLU
import pickle
import ast

data=pd.read_csv('aloo.csv')

"""#PUNYA MICELL COBA"""

# Process the data
data['ingredients'] = data['ingredients'].apply(lambda x: ' '.join(ast.literal_eval(x)))
data['tags'] = data['tags'].apply(eval)

# MultiLabelBinarizer for tags
mlb = MultiLabelBinarizer()
tags_encoded = mlb.fit_transform(data['tags'])
with open('mlb1.pkl', 'wb') as f:
    pickle.dump(mlb, f)

# TfidfVectorizer for ingredients
vectorizer = TfidfVectorizer(max_features=5000)
ingredients_tfidf = vectorizer.fit_transform(data['ingredients'])
with open('vectorize.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    ingredients_tfidf, tags_encoded, test_size=0.2
)

input_dim = ingredients_tfidf.shape[1]
output_dim = tags_encoded.shape[1]

"""#PUNYA CHERYL"""

# Process the data
data['ingredients'] = data['ingredients'].apply(lambda x: ' '.join(eval(x)))
data['tags'] = data['tags'].apply(eval)

# MultiLabelBinarizer for tags
mlb = MultiLabelBinarizer()
tags_encoded = mlb.fit_transform(data['tags'])
joblib.dump(mlb, 'mlb1.pkl')  # Save the MultiLabelBinarizer

# TfidfVectorizer for ingredients
vectorizer = TfidfVectorizer(max_features=5000)
ingredients_tfidf = vectorizer.fit_transform(data['ingredients'])
joblib.dump(vectorizer, 'vectorizer1.pkl')  # Save the TfidfVectorizer

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    ingredients_tfidf, tags_encoded, test_size=0.2
)

input_dim = ingredients_tfidf.shape[1]
output_dim = tags_encoded.shape[1]

"""#**OPSI 1**"""

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(input_dim,), sparse=True),  # Sparse input
    tf.keras.layers.Dense(512),  # Hidden layer with 512 neurons
    BatchNormalization(),  # Batch normalization
    LeakyReLU(alpha=0.1),  # Advanced activation
    tf.keras.layers.Dropout(0.3),  # Increased dropout for regularization

    tf.keras.layers.Dense(256),
    BatchNormalization(),
    LeakyReLU(alpha=0.1),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Dense(14, activation='sigmoid')  # Multilabel output
])

# Compile the model
model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),  # SGD with momentum
    loss='binary_crossentropy',
    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),
             tf.keras.metrics.Precision(name='precision'),
             tf.keras.metrics.Recall(name='recall')]
)

# Early stopping to prevent overfitting
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

# Train the model
history = model.fit(
    X_train,
    y_train,
    validation_data=(X_test, y_test),
    epochs=50,
    batch_size=128,  # Reduced batch size for better convergence
    callbacks=[early_stopping]
)

# Evaluate the model
loss, accuracy, precision, recall = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")

!pip install tensorflowjs

#buat convert ke tfjs
!tensorflowjs_converter --input_format=keras /content/model.h5 /tmp/modelproject

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

import matplotlib.pyplot as plt #pake droupout 0.3, pake 64
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

# New ingredients input
new_ingredients =['tomato','salt', 'ketchup']

# Preprocess the input
new_ingredients_str = ' '.join(new_ingredients)  # Convert to a single string
new_ingredients_vectorized = vectorizer.transform([new_ingredients_str])  # Transform to sparse matrix

# Predict tags
predicted_probabilities = model.predict(new_ingredients_vectorized)

# Apply a threshold to convert probabilities to binary predictions
threshold = 0.5
predicted_tags_binary = (predicted_probabilities > threshold).astype(int)

# Decode the predictions to get the tag names
predicted_tags = mlb.inverse_transform(predicted_tags_binary)

print("Predicted Tags:", predicted_tags)

from google.colab import files
model.save('model.h5')
files.download('model.h5')

"""#OPSI 2"""

model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(input_dim,), sparse=True),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256,activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(output_dim, activation='sigmoid')  # Multi-label classification
])


model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9),
    loss='binary_crossentropy',
    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),
             tf.keras.metrics.Precision(name='precision'),
             tf.keras.metrics.Recall(name='recall')]
)

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)


history = model.fit(
    X_train,
    y_train,
    validation_data=(X_test, y_test),
    epochs=50,
    batch_size=128,  # Reduced batch size for better convergence
    callbacks=[early_stopping]
)

# Evaluate the model
loss, accuracy, precision, recall = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

import matplotlib.pyplot as plt #gak pake droupout 0.3, tapi pake 64
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

# New ingredients input
new_ingredients =['tomato','egg','cheese','breadcrumb']

# Preprocess the input
new_ingredients_str = ' '.join(new_ingredients)  # Convert to a single string
new_ingredients_vectorized = vectorizer.transform([new_ingredients_str])  # Transform to sparse matrix

# Predict tags
predicted_probabilities = model.predict(new_ingredients_vectorized)

# Apply a threshold to convert probabilities to binary predictions
threshold = 0.5
predicted_tags_binary = (predicted_probabilities > threshold).astype(int)

# Decode the predictions to get the tag names
predicted_tags = mlb.inverse_transform(predicted_tags_binary)

print("Predicted Tags:", predicted_tags)

"""#OPSI 3"""

model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(input_dim,), sparse=True),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256,activation='relu'),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(output_dim, activation='sigmoid')  # Multi-label classification
])


model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),
    loss='binary_crossentropy',
    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),
             tf.keras.metrics.Precision(name='precision'),
             tf.keras.metrics.Recall(name='recall')]
)

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)


history = model.fit(
    X_train,
    y_train,
    validation_data=(X_test, y_test),
    epochs=50,
    batch_size=128,  # Reduced batch size for better convergence
    callbacks=[early_stopping]
)

# Evaluate the model
loss, accuracy, precision, recall = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")

import matplotlib.pyplot as plt #gak pake droupout 0.3, tapi pake 64
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

import matplotlib.pyplot as plt #pake droupout 0.3, pake 64
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

# New ingredients input
new_ingredients =['tomato','egg','cheese','breadcrumb']

# Preprocess the input
new_ingredients_str = ' '.join(new_ingredients)  # Convert to a single string
new_ingredients_vectorized = vectorizer.transform([new_ingredients_str])  # Transform to sparse matrix

# Predict tags
predicted_probabilities = model.predict(new_ingredients_vectorized)

# Apply a threshold to convert probabilities to binary predictions
threshold = 0.5
predicted_tags_binary = (predicted_probabilities > threshold).astype(int)

# Decode the predictions to get the tag names
predicted_tags = mlb.inverse_transform(predicted_tags_binary)

print("Predicted Tags:", predicted_tags)